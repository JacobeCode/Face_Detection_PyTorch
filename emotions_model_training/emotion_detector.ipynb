{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "# For first run only to set proper directory\n",
    "# os.chdir('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SQL.connector import connector\n",
    "from emotions_model_training.EmotionsDataset import EmotionsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramteres for scripts (implement proportion of sets)\n",
    "sets_proportion = [0.6, 0.2, 0.2]       # train / valid / test\n",
    "batch = 64                              # batch size\n",
    "do_shuffle = True                       # shuffling data in loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\Face_Detection_PyTorch\\SQL\\connector.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>face_id_image</th>\n",
       "      <th>box_top</th>\n",
       "      <th>box_left</th>\n",
       "      <th>box_right</th>\n",
       "      <th>box_bottom</th>\n",
       "      <th>box_confidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distaste_mother_319.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>664</td>\n",
       "      <td>712</td>\n",
       "      <td>168</td>\n",
       "      <td>33.1615</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distaste_mother_498.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>150</td>\n",
       "      <td>222</td>\n",
       "      <td>7.75454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distaste_mother_58.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>136</td>\n",
       "      <td>120</td>\n",
       "      <td>72.9418</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distaste_mother_623.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>321</td>\n",
       "      <td>79.3727</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distaste_mother_667.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>180</td>\n",
       "      <td>315</td>\n",
       "      <td>202</td>\n",
       "      <td>61.9211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91788</th>\n",
       "      <td>surprised_expression_546.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "      <td>37.7117</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91789</th>\n",
       "      <td>surprised_expression_381.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>91.6307</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91790</th>\n",
       "      <td>surprised_expression_395.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>95</td>\n",
       "      <td>258</td>\n",
       "      <td>190</td>\n",
       "      <td>96.2861</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91791</th>\n",
       "      <td>ecstatic_asian_31.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>136</td>\n",
       "      <td>184</td>\n",
       "      <td>108</td>\n",
       "      <td>39.9223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91792</th>\n",
       "      <td>surprised_expression_394.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>152</td>\n",
       "      <td>161</td>\n",
       "      <td>77.7758</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91793 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image face_id_image box_top box_left box_right  \\\n",
       "0           distaste_mother_319.jpg             3     120      664       712   \n",
       "1           distaste_mother_498.jpg             1     175      103       150   \n",
       "2            distaste_mother_58.jpg             0      72       88       136   \n",
       "3           distaste_mother_623.jpg             0     254        5        72   \n",
       "4           distaste_mother_667.jpg             0      67      180       315   \n",
       "...                             ...           ...     ...      ...       ...   \n",
       "91788  surprised_expression_546.jpg             0      70       70       351   \n",
       "91789  surprised_expression_381.jpg             0      51       61       117   \n",
       "91790  surprised_expression_395.jpg             0      27       95       258   \n",
       "91791         ecstatic_asian_31.jpg             0      60      136       184   \n",
       "91792  surprised_expression_394.jpg             0      47       38       152   \n",
       "\n",
       "      box_bottom box_confidence label  \n",
       "0            168        33.1615     6  \n",
       "1            222        7.75454     3  \n",
       "2            120        72.9418     6  \n",
       "3            321        79.3727     6  \n",
       "4            202        61.9211     1  \n",
       "...          ...            ...   ...  \n",
       "91788        351        37.7117     5  \n",
       "91789        107        91.6307     5  \n",
       "91790        190        96.2861     5  \n",
       "91791        108        39.9223     3  \n",
       "91792        161        77.7758     5  \n",
       "\n",
       "[91793 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the dataset with SQL query and dispaying for insight\n",
    "db_dir = \"D:\\\\Repos\\\\Face_Detection_PyTorch\\\\dataset\\\\expression_dataset\\\\data\\\\data\\\\image\\\\origin\"\n",
    "\n",
    "conn = connector()\n",
    "db = conn.query(f'SELECT * FROM dbo.label')\n",
    "\n",
    "display(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sizes of prepared datasets:\n",
      "Train shape: 55075 (60%)\n",
      "Valid shape: 18359 (20%)\n",
      "Test shape: 18359 (20%)\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into sets (train, test, valid) - with renumeration\n",
    "train, val_test = train_test_split(db, test_size=0.4, train_size=0.6, random_state=42, stratify=db['label'])\n",
    "valid, test = train_test_split(val_test, test_size=0.5, train_size=0.5, random_state=42, stratify=val_test['label'])\n",
    "\n",
    "train, valid, test = train.reset_index(drop=True), valid.reset_index(drop=True), test.reset_index(drop=True)\n",
    "\n",
    "print(\"Checking sizes of prepared datasets:\")\n",
    "print(\"Train shape: \" + str(train.shape[0]) + \" (\" + str(round((train.shape[0]/db.shape[0])*100)) + \"%)\")\n",
    "print(\"Valid shape: \" + str(valid.shape[0]) + \" (\" + str(round((valid.shape[0]/db.shape[0])*100)) + \"%)\")\n",
    "print(\"Test shape: \" + str(test.shape[0]) + \" (\" + str(round((test.shape[0]/db.shape[0])*100)) + \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init for datasets with PyTorch class\n",
    "train_dataset = EmotionsDataset(train, db_dir)\n",
    "\n",
    "# Fixing valid and test dataset to same sizes (for convinience with NN architecture)\n",
    "horz, vert = train_dataset.horz_max, train_dataset.vert_max\n",
    "\n",
    "valid_dataset = EmotionsDataset(valid, db_dir, horz, vert)\n",
    "test_dataset = EmotionsDataset(test, db_dir, horz, vert)\n",
    "\n",
    "# Init for dataloaders with default batch = 64\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch, shuffle=do_shuffle, drop_last=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=batch, shuffle=do_shuffle, drop_last=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch, shuffle=do_shuffle, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images: 2117 x 2117\n"
     ]
    }
   ],
   "source": [
    "# Checking maximal size - in theory it can vary, but it depends from split of dataset\n",
    "print(\"Size of images: \" + str(horz) + \" x \" + str(vert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# Checking CUDA avalibility\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Using \" + str(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
